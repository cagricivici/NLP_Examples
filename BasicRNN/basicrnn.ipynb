{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":19018,"databundleVersionId":2703900,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:41:55.794199Z","iopub.execute_input":"2025-02-11T14:41:55.794554Z","iopub.status.idle":"2025-02-11T14:41:55.798366Z","shell.execute_reply.started":"2025-02-11T14:41:55.794529Z","shell.execute_reply":"2025-02-11T14:41:55.797543Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential  # ✅ Corrected\nfrom tensorflow.keras.layers import LSTM, GRU, SimpleRNN  # ✅ Corrected\nfrom tensorflow.keras.layers import Dense, Activation, Dropout  # ✅ Corrected\nfrom tensorflow.keras.layers import Embedding  # ✅ Corrected\n\nfrom tensorflow.keras.utils import to_categorical  # ✅ Corrected\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\nfrom tensorflow.keras.preprocessing.text import Tokenizer  # ✅ Correct\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom keras.callbacks import EarlyStopping\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:42:24.760087Z","iopub.execute_input":"2025-02-11T14:42:24.760373Z","iopub.status.idle":"2025-02-11T14:42:28.815223Z","shell.execute_reply.started":"2025-02-11T14:42:24.760343Z","shell.execute_reply":"2025-02-11T14:42:28.813825Z"}},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1739284946.146078    5597 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: ===\nlearning/45eac/tfrc/runtime/common_lib.cc:230\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\ndtrain = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\ndval = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\ndtest = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:42:35.191799Z","iopub.execute_input":"2025-02-11T14:42:35.192397Z","iopub.status.idle":"2025-02-11T14:42:37.085448Z","shell.execute_reply.started":"2025-02-11T14:42:35.192363Z","shell.execute_reply":"2025-02-11T14:42:37.084274Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Initialize TPU with the given name\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local') # Detect TPU\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\nstrategy = tf.distribute.TPUStrategy(tpu)\n\nprint(\"✅ TPU Successfully Connected\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:42:38.251319Z","iopub.execute_input":"2025-02-11T14:42:38.251618Z","iopub.status.idle":"2025-02-11T14:42:46.204464Z","shell.execute_reply.started":"2025-02-11T14:42:38.251594Z","shell.execute_reply":"2025-02-11T14:42:46.203473Z"}},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1739284961.739265    5597 service.cc:148] XLA service 0x5835165d8350 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1739284961.739312    5597 service.cc:156]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1739284961.739316    5597 service.cc:156]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1739284961.739319    5597 service.cc:156]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1739284961.739322    5597 service.cc:156]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1739284961.739324    5597 service.cc:156]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1739284961.739328    5597 service.cc:156]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1739284961.739332    5597 service.cc:156]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1739284961.739334    5597 service.cc:156]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n✅ TPU Successfully Connected\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"dtrain","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:43:56.669715Z","iopub.execute_input":"2025-02-11T14:43:56.670043Z","iopub.status.idle":"2025-02-11T14:43:56.683673Z","shell.execute_reply.started":"2025-02-11T14:43:56.670017Z","shell.execute_reply":"2025-02-11T14:43:56.682531Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                      id                                       comment_text  \\\n0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n...                  ...                                                ...   \n223544  fff8f64043129fa2  :Jerome, I see you never got around to this…! ...   \n223545  fff9d70fe0722906  ==Lucky bastard== \\n http://wikimediafoundatio...   \n223546  fffa8a11c4378854  ==shame on you all!!!== \\n\\n You want to speak...   \n223547  fffac2a094c8e0e2  MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...   \n223548  fffb5451268fb5ba  \" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...   \n\n        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n0           0             0        0       0       0              0  \n1           0             0        0       0       0              0  \n2           0             0        0       0       0              0  \n3           0             0        0       0       0              0  \n4           0             0        0       0       0              0  \n...       ...           ...      ...     ...     ...            ...  \n223544      0             0        0       0       0              0  \n223545      0             0        0       0       0              0  \n223546      0             0        0       0       0              0  \n223547      1             0        1       0       1              0  \n223548      0             0        0       0       0              0  \n\n[223549 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>223544</th>\n      <td>fff8f64043129fa2</td>\n      <td>:Jerome, I see you never got around to this…! ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>223545</th>\n      <td>fff9d70fe0722906</td>\n      <td>==Lucky bastard== \\n http://wikimediafoundatio...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>223546</th>\n      <td>fffa8a11c4378854</td>\n      <td>==shame on you all!!!== \\n\\n You want to speak...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>223547</th>\n      <td>fffac2a094c8e0e2</td>\n      <td>MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>223548</th>\n      <td>fffb5451268fb5ba</td>\n      <td>\" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>223549 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"dtest","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:44:00.470938Z","iopub.execute_input":"2025-02-11T14:44:00.471262Z","iopub.status.idle":"2025-02-11T14:44:00.481077Z","shell.execute_reply.started":"2025-02-11T14:44:00.471234Z","shell.execute_reply":"2025-02-11T14:44:00.480022Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"          id                                            content lang\n0          0  Doctor Who adlı viki başlığına 12. doctor olar...   tr\n1          1   Вполне возможно, но я пока не вижу необходимо...   ru\n2          2  Quindi tu sei uno di quelli   conservativi  , ...   it\n3          3  Malesef gerçekleştirilmedi ancak şöyle bir şey...   tr\n4          4  :Resim:Seldabagcan.jpg resminde kaynak sorunu ...   tr\n...      ...                                                ...  ...\n63807  63807  No, non risponderò, come preannunciato. Prefer...   it\n63808  63808  Ciao, I tecnici della Wikimedia Foundation sta...   it\n63809  63809  innnazitutto ti ringrazio per i ringraziamenti...   it\n63810  63810   Kaç olumlu oy gerekiyor? Şu an 7 oldu.  Hayır...   tr\n63811  63811   Te pido disculpas. La verdad es que no me per...   es\n\n[63812 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>content</th>\n      <th>lang</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Doctor Who adlı viki başlığına 12. doctor olar...</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Вполне возможно, но я пока не вижу необходимо...</td>\n      <td>ru</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Quindi tu sei uno di quelli   conservativi  , ...</td>\n      <td>it</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey...</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu ...</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>63807</th>\n      <td>63807</td>\n      <td>No, non risponderò, come preannunciato. Prefer...</td>\n      <td>it</td>\n    </tr>\n    <tr>\n      <th>63808</th>\n      <td>63808</td>\n      <td>Ciao, I tecnici della Wikimedia Foundation sta...</td>\n      <td>it</td>\n    </tr>\n    <tr>\n      <th>63809</th>\n      <td>63809</td>\n      <td>innnazitutto ti ringrazio per i ringraziamenti...</td>\n      <td>it</td>\n    </tr>\n    <tr>\n      <th>63810</th>\n      <td>63810</td>\n      <td>Kaç olumlu oy gerekiyor? Şu an 7 oldu.  Hayır...</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>63811</th>\n      <td>63811</td>\n      <td>Te pido disculpas. La verdad es que no me per...</td>\n      <td>es</td>\n    </tr>\n  </tbody>\n</table>\n<p>63812 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Data Preprocessing: \n\n**Consider this example as binary classification with only toxic**","metadata":{}},{"cell_type":"code","source":"dtrain = dtrain[['id','comment_text','toxic']]\ndtrain.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:44:03.962806Z","iopub.execute_input":"2025-02-11T14:44:03.963182Z","iopub.status.idle":"2025-02-11T14:44:03.983774Z","shell.execute_reply.started":"2025-02-11T14:44:03.963151Z","shell.execute_reply":"2025-02-11T14:44:03.982699Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0\n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0\n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0\n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0\n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"each_len = []\n\nfor k in dtrain['comment_text']:\n    each_len.append(len(k.split(' ')))\n    \ndtrain['comment_len'] = each_len","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:44:07.135594Z","iopub.execute_input":"2025-02-11T14:44:07.135907Z","iopub.status.idle":"2025-02-11T14:44:08.104605Z","shell.execute_reply.started":"2025-02-11T14:44:07.135881Z","shell.execute_reply":"2025-02-11T14:44:08.103015Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_5597/1305875470.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  dtrain['comment_len'] = each_len\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"dtrain_sorted = dtrain.groupby('comment_len')[['comment_text']].max().sort_values(by='comment_len', ascending=False).reset_index()\n\ndtrain_sorted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:44:10.855446Z","iopub.execute_input":"2025-02-11T14:44:10.855750Z","iopub.status.idle":"2025-02-11T14:44:10.988821Z","shell.execute_reply.started":"2025-02-11T14:44:10.855724Z","shell.execute_reply":"2025-02-11T14:44:10.987770Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"      comment_len                                       comment_text\n0            2834  \"   \\n = = R e g a r d i n g   K a r e l = =  ...\n1            2681  \" \\n\\n ==Hey sexy== \\n Quit sucking so much ha...\n2            2321  C O M M I E - F U C K E R C O M M I E - F U C ...\n3            2273  \"\\n\\nAs near as I can tell, wikipedia has no a...\n4            2071  == me editing bad. == \\n\\n well' i want to be ...\n...           ...                                                ...\n1020            5                       일이삼사오육칠팔구하고십이요 에헤헤 으헤 으헤 으허허\n1021            4                               괴로운 변명을 하는 사람이다-_-;;\n1022            3                               → English Wikipedia←\n1023            2  ขอบคุณครับคำแนะนำครับ ใส่แหล่งอ้างอิงเรียบร้อย...\n1024            1                                                  ~\n\n[1025 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_len</th>\n      <th>comment_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2834</td>\n      <td>\"   \\n = = R e g a r d i n g   K a r e l = =  ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2681</td>\n      <td>\" \\n\\n ==Hey sexy== \\n Quit sucking so much ha...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2321</td>\n      <td>C O M M I E - F U C K E R C O M M I E - F U C ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2273</td>\n      <td>\"\\n\\nAs near as I can tell, wikipedia has no a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2071</td>\n      <td>== me editing bad. == \\n\\n well' i want to be ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1020</th>\n      <td>5</td>\n      <td>일이삼사오육칠팔구하고십이요 에헤헤 으헤 으헤 으허허</td>\n    </tr>\n    <tr>\n      <th>1021</th>\n      <td>4</td>\n      <td>괴로운 변명을 하는 사람이다-_-;;</td>\n    </tr>\n    <tr>\n      <th>1022</th>\n      <td>3</td>\n      <td>→ English Wikipedia←</td>\n    </tr>\n    <tr>\n      <th>1023</th>\n      <td>2</td>\n      <td>ขอบคุณครับคำแนะนำครับ ใส่แหล่งอ้างอิงเรียบร้อย...</td>\n    </tr>\n    <tr>\n      <th>1024</th>\n      <td>1</td>\n      <td>~</td>\n    </tr>\n  </tbody>\n</table>\n<p>1025 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"#print(dtrain_sorted.iloc[0]['comment_text'])\n#print(dtrain_sorted.iloc[0]['comment_len'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, roc_curve, auc\n\ndef roc_auc_cal(pred,y):\n    a=roc_auc_score(y, pred)\n    return a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:33:33.900777Z","iopub.execute_input":"2025-02-11T14:33:33.901230Z","iopub.status.idle":"2025-02-11T14:33:33.905731Z","shell.execute_reply.started":"2025-02-11T14:33:33.901197Z","shell.execute_reply":"2025-02-11T14:33:33.904723Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#EXAMPLE\n'''\n# Simulated dataset\ny_true = [0, 0, 1, 1]\ny_scores = [0.1, 0.4, 0.35, 0.8]\n\nprint(roc_auc_cal(y_scores,y_true))  ---- 0.75\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:09:00.869536Z","iopub.execute_input":"2025-02-11T14:09:00.869904Z","iopub.status.idle":"2025-02-11T14:09:00.875853Z","shell.execute_reply.started":"2025-02-11T14:09:00.869874Z","shell.execute_reply":"2025-02-11T14:09:00.874805Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'\\n# Simulated dataset\\ny_true = [0, 0, 1, 1]\\ny_scores = [0.1, 0.4, 0.35, 0.8]\\n\\nprint(roc_auc_cal(y_scores,y_true))  ---- 0.75\\n'"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"dtrain","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Converting text to lowercase:\nimport re\ndef convt_lower(data):\n    tmp = []\n    for e in data:\n        tmp.append(e.lower())\n    return tmp\n\ndef remove_specialchar(data):\n    tmp = []\n    for e in data:\n        e = e.replace('\\n',' ')\n        tmp.append(re.sub(r'[^a-zA-Z0-9\\s]', '', e))\n    return tmp\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:44:18.650670Z","iopub.execute_input":"2025-02-11T14:44:18.650983Z","iopub.status.idle":"2025-02-11T14:44:18.656102Z","shell.execute_reply.started":"2025-02-11T14:44:18.650956Z","shell.execute_reply":"2025-02-11T14:44:18.654763Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"comment_lc = convt_lower(dtrain['comment_text'])\ncomment_punc = remove_specialchar(comment_lc)\ndtrain['comment_pro']=comment_punc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:44:21.142368Z","iopub.execute_input":"2025-02-11T14:44:21.142682Z","iopub.status.idle":"2025-02-11T14:44:23.617830Z","shell.execute_reply.started":"2025-02-11T14:44:21.142654Z","shell.execute_reply":"2025-02-11T14:44:23.616777Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_5597/2919373115.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  dtrain['comment_pro']=comment_punc\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"**Takeaways here:**\n\n> I need to tokenizer them then i am going to list it into sequence. For doing that, I splitted the data into train and test. But only train data goes to Tokenizer.fit_on_text. If I put train and test data together, tokenization process would be done by considering test data which means the model would see the test data. but it should not see. test data should be unseen.","metadata":{}},{"cell_type":"code","source":"#first split the data:\ny = dtrain['toxic']\nx = dtrain['comment_pro']\nx_train,x_test,y_train,y_test = train_test_split(x.values,y.values,random_state=42,test_size=0.25, shuffle=True)\n\nmaxlen = 2000\n#Initialize the tokenizer\ntoken = Tokenizer(num_words=maxlen, oov_token=\"<OOV>\") \ntoken.fit_on_texts(x_train)\nvocab_size=len(token.word_index)\n\n#Apply the tokenizer here:\nx_train_seq = token.texts_to_sequences(x_train) \nx_test_seq = token.texts_to_sequences(x_test)   #Truncation just so that max len of data is 2000 words\n\n#Truncation did not take place before. I will to it now!\nfor e in x_train_seq:\n    if len(e)>2000:\n        print(len(e))\n        print('blinked!')\n        break\n\nx_train_pad = pad_sequences(x_train_seq, maxlen=maxlen, padding='post', truncating='post') #post or pre\nx_test_pad = pad_sequences(x_test_seq, maxlen=maxlen, padding='post', truncating='post') #post or pre\n\n#now check whether the truncating is done succesfully:\nchecker = True\nfor e in x_train_pad:\n    if len(e) > 2000:\n        print('blinked!')\n        checker == False\nif checker == True:\n    print('truncating is applied sucessfully')\nelse:\n    print('there is a problem in truncating')\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:44:29.740876Z","iopub.execute_input":"2025-02-11T14:44:29.741222Z","iopub.status.idle":"2025-02-11T14:44:46.758822Z","shell.execute_reply.started":"2025-02-11T14:44:29.741197Z","shell.execute_reply":"2025-02-11T14:44:46.757546Z"}},"outputs":[{"name":"stdout","text":"2142\nblinked!\ntruncating is applied sucessfully\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"vocab_size=len(token.word_index)\nprint(vocab_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:46:15.431122Z","iopub.execute_input":"2025-02-11T14:46:15.431467Z","iopub.status.idle":"2025-02-11T14:46:15.435777Z","shell.execute_reply.started":"2025-02-11T14:46:15.431439Z","shell.execute_reply":"2025-02-11T14:46:15.434784Z"}},"outputs":[{"name":"stdout","text":"270060\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"**RNN(Embedding layer needs 3 input):**\n- num_vocab\n- embedding dim\n- inp_len\n\n**Takeaways_1:** (num_vocab)\n\n> Embedding layer needs to know how many words exists in the vocabulary to assign embedding properly. Here created an matrix for the entire vocabulary. Thats why we need make the matrix prepare for how many different inputs will come.\n>\n**Takeaways_2:** (embedding_dim)\n\n> Embedding layer need to know each token has how many feature vectors. When you assign lets say 100, each token will have 100 different embedding vectors that refers to features.\n> Bigger vector of feature, slower training time, better results (also overfiting risk)\n> Lesser vector of feature, faster training time, worse results ","metadata":{}},{"cell_type":"code","source":"loss = 'binary_crossentropy'\noptimizer = 'adam'\nmetrics = ['accuracy']\n\nwith strategy.scope():\n    model = Sequential()\n\n    model.add(Embedding(vocab_size,100,input_length = maxlen)) #embedding_dim,output_dim,inp_len\n    model.add(SimpleRNN(100))\n    model.add(Dense(1,activation='sigmoid'))\n\n    model.build(input_shape=(None, 2000))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:46:19.962299Z","iopub.execute_input":"2025-02-11T14:46:19.962706Z","iopub.status.idle":"2025-02-11T14:46:24.146740Z","shell.execute_reply.started":"2025-02-11T14:46:19.962653Z","shell.execute_reply":"2025-02-11T14:46:24.145547Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\nI0000 00:00:1739285180.031281    5597 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │    \u001b[38;5;34m27,006,000\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m20,100\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">27,006,000</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,026,201\u001b[0m (103.10 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,026,201</span> (103.10 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,026,201\u001b[0m (103.10 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,026,201</span> (103.10 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"model.fit(x_train_pad,y_train,epochs = 5, batch_size=128,validation_data = (x_test_pad,y_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver('local')\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)  # TPU Strategy\n    print(\"✅ TPU Successfully Connected!\")\nexcept ValueError:\n    strategy = tf.distribute.get_strategy()\n    print(\"❌ TPU Not Found, using default strategy.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T14:41:34.924540Z","iopub.execute_input":"2025-02-11T14:41:34.924830Z","iopub.status.idle":"2025-02-11T14:41:45.979326Z","shell.execute_reply.started":"2025-02-11T14:41:34.924803Z","shell.execute_reply":"2025-02-11T14:41:45.977784Z"}},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1739284895.233048    4345 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:230\nException ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x797bc461e7a0>>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 757, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\n  File \"/usr/local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 554, in sigint_handler\n    raise KeyboardInterrupt\nKeyboardInterrupt: \n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1739284901.931716    4345 service.cc:148] XLA service 0x56fcd0a01f80 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1739284901.931765    4345 service.cc:156]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1739284901.931769    4345 service.cc:156]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1739284901.931772    4345 service.cc:156]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1739284901.931775    4345 service.cc:156]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1739284901.931778    4345 service.cc:156]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1739284901.931780    4345 service.cc:156]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1739284901.931783    4345 service.cc:156]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1739284901.931786    4345 service.cc:156]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n✅ TPU Successfully Connected!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"","metadata":{}}]}